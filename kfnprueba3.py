# -*- coding: utf-8 -*-
"""kfnprueba3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dkWkJy0nYFcAkNfLiMlvDX5ZiAvudHNt

MODELO FUNCIONAL EN VERSIÓN PRELIMINAR
POR: JORGE CHAMORRO
"""

import tensorflow as tf
import numpy as np
from tensorflow.keras.utils import to_categorical

!mkdir dataset
!mkdir dataset/S
!mkdir dataset/D
!mkdir dataset/N

import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Directorio que contiene tus subdirectorios
directorio_principal = '/content/dataset'

# Obtener la lista de subdirectorios
subdirectorios = os.listdir(directorio_principal)

# Mostrar un ejemplo de cada subdirectorio
for subdirectorio in subdirectorios:
    # Construir la ruta completa al subdirectorio
    ruta_subdirectorio = os.path.join(directorio_principal, subdirectorio)

    # Obtener la lista de archivos en el subdirectorio
    archivos = os.listdir(ruta_subdirectorio)

    # Seleccionar el primer archivo como ejemplo
    ejemplo = archivos[0]

    # Construir la ruta completa al ejemplo
    ruta_ejemplo = os.path.join(ruta_subdirectorio, ejemplo)

    # Mostrar el ejemplo
    imagen = mpimg.imread(ruta_ejemplo)
    plt.imshow(imagen)
    plt.title(subdirectorio)
    plt.axis('off')
    plt.show()

#Aumento de datos
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Crear el dataset generador con aumentos específicos
datagen = ImageDataGenerator(
    rescale=1. / 255,
    height_shift_range=0.1,  # Traslación vertical
    zoom_range=0.1,  # Zoom in y out
    brightness_range=[0.8, 1.2],  # Ajuste de brillo
    validation_split=0.2  # 20% para pruebas
)

# Generadores para sets de entrenamiento y pruebas
data_gen_entrenamiento = datagen.flow_from_directory('/content/dataset', target_size=(400, 1000),
                                                     batch_size=10, shuffle=True, subset='training',
                                                     color_mode='grayscale')
data_gen_pruebas = datagen.flow_from_directory('/content/dataset', target_size=(400, 1000),
                                               batch_size=10, shuffle=True, subset='validation',
                                               color_mode='grayscale')

# Imprimir 5 ejemplos del generador de entrenamiento
num_ejemplos_mostrados = 5
for imagen, etiqueta in data_gen_entrenamiento:
    for i in range(num_ejemplos_mostrados):
        plt.subplot(num_ejemplos_mostrados, 1, i + 1)
        plt.xticks([])
        plt.yticks([])
        plt.imshow(imagen[i].squeeze(), cmap='gray')
        plt.title(f'Etiqueta: {etiqueta[i]}')
    plt.show()
    break  # Detener después de mostrar un lote de ejemplos

# Verificar cuántas imágenes se utilizarán para pruebas
num_imagenes_pruebas = len(data_gen_pruebas.filenames)
print(f"Se utilizarán {num_imagenes_pruebas} imágenes para pruebas.")

#Modelo
modelo = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(20, (3,3), activation='relu', input_shape=(400, 1000, 1)),
    tf.keras.layers.MaxPooling2D(2, 2),

    tf.keras.layers.Conv2D(40, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(20, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(40, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(20, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),

    tf.keras.layers.Conv2D(40, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),


    tf.keras.layers.Dropout(0.7),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(100, activation='relu'),
    tf.keras.layers.Dense(3, activation="softmax")
])

#Compilación
modelo.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

TAMANO_LOTE = 10

#Entrenamiento
print("Entrenando modelo...");
epocas=40
historial = modelo.fit(
    data_gen_entrenamiento,
    epochs=epocas,
    batch_size=TAMANO_LOTE,
    validation_data=(data_gen_pruebas),
    steps_per_epoch=int(np.ceil(200/ float(TAMANO_LOTE))),
    validation_steps=int(np.ceil(40/ float(TAMANO_LOTE)))
)

print("Modelo entrenado!");

modelo.summary()

!mkdir test

from PIL import Image
import requests
from io import BytesIO
import cv2


def categorizar(ruta_archivo):
    img = Image.open(ruta_archivo)
    img = img.convert('L')  # Convertir a escala de grises
    img = np.array(img).astype(float) / 255  # Normalizar valores de píxeles
    img = cv2.resize(img, (1000, 400))  # Redimensionar la imagen al tamaño esperado por el modelo
    img = np.expand_dims(img, axis=-1)  # Añadir una dimensión para el canal (escala de grises)
    img = np.expand_dims(img, axis=0)  # Añadir una dimensión para el lote
    prediccion = modelo.predict(img)
    return np.argmax(prediccion, axis=-1)

#0 = D, 1 = N , 2 = S
ruta_archivo = '/content/test/DY01.jpg' #debe ser 2
prediccion = categorizar (ruta_archivo)
print(prediccion)

ruta_archivo = '/content/test/DY02.jpg' #debe ser 2
prediccion = categorizar (ruta_archivo)
print(prediccion)

ruta_archivo = '/content/test/DY03.jpg' #debe ser 2
prediccion = categorizar (ruta_archivo)
print(prediccion)

ruta_archivo = '/content/test/DY04.jpg' #debe ser 0
prediccion = categorizar (ruta_archivo)
print(prediccion)

ruta_archivo = '/content/test/DY05.jpg' #debe ser 0
prediccion = categorizar (ruta_archivo)
print(prediccion)

ruta_archivo = '/content/test/DY06.jpg' #debe ser 0
prediccion = categorizar (ruta_archivo)
print(prediccion)

ruta_archivo = '/content/test/DY07.jpg' #debe ser 1
prediccion = categorizar (ruta_archivo)
print(prediccion)

ruta_archivo = '//content/test/DY08.jpg' #debe ser 1
prediccion = categorizar (ruta_archivo)
print(prediccion)

ruta_archivo = '/content/test/DY09.jpg' #debe ser 1
prediccion = categorizar (ruta_archivo)
print(prediccion)

ruta_archivo = '/content/test/MFC01.jpg' #debe ser 2
prediccion = categorizar (ruta_archivo)
print(prediccion)

ruta_archivo = '/content/test/MFC02.jpg' #debe ser 2
prediccion = categorizar (ruta_archivo)
print(prediccion)

ruta_archivo = '/content/test/MFC03.jpg' #debe ser 0
prediccion = categorizar (ruta_archivo)
print(prediccion)

ruta_archivo = '/content/test/MFC04.jpg' #debe ser 0
prediccion = categorizar (ruta_archivo)
print(prediccion)

ruta_archivo = '/content/test/MFC05.jpg' #debe ser 1
prediccion = categorizar (ruta_archivo)
print(prediccion)

ruta_archivo = '/content/test/MFC06.jpg' #debe ser 1
prediccion = categorizar (ruta_archivo)
print(prediccion)

print(historial.history)

#Graficas de precisión
acc = historial.history['accuracy']
val_acc = historial.history['val_accuracy']
loss = historial.history['loss']
val_loss = historial.history['val_loss']

epochs = range(1, len(acc) + 1)

plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.plot(epochs, acc, 'r', label='Accuracy de entrenamiento')
plt.plot(epochs, val_acc, 'b', label='Accuracy de validación')
plt.title('Accuracy de entrenamiento y validación')
plt.xlabel('Épocas')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(epochs, loss, 'r', label='Pérdida de entrenamiento')
plt.plot(epochs, val_loss, 'b', label='Pérdida de validación')
plt.title('Pérdida de entrenamiento y validación')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.legend()

plt.show()

#Crear la carpeta para exportarla a TF Serving
modelo.save('modelo_myfnc.h5')